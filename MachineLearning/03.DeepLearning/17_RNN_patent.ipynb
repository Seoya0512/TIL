{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17_RNN_patent.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "415uhIj6DA7G"
      },
      "source": [
        "https://towardsdatascience.com/recurrent-neural-networks-by-example-in-python-ffd204f99470"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bw40GU3cL2M"
      },
      "source": [
        "# Using a Recurrent Neural Network to write Patent Abstracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZoRtExM4NQ2",
        "outputId": "168cc237-6636-46f9-dafa-ca73c8b5fd0d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMGCqb408mLS"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL09cH5M4Wut"
      },
      "source": [
        "patent = '/content/drive/MyDrive/Data/RNN_example/neural_network_patent_query.csv'\n",
        "pretrain = '/content/drive/MyDrive/Data/RNN_example/pre-trained-rnn.h5'\n",
        "embedding1 = '/content/drive/MyDrive/Data/RNN_example/train-embeddings-rnn.h5'\n",
        "embedding2 = '/content/drive/MyDrive/Data/RNN_example/train-embeddings-rnn-2-layers.h5'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ASZgezRGOOp"
      },
      "source": [
        "- 활용 함수 생성 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDa_rYJZ-WER",
        "outputId": "56aa4435-f53e-4168-e9ff-5094d1e37910"
      },
      "source": [
        "%%writefile utils.py\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Masking\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from itertools import chain\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import re\n",
        "\n",
        "RANDOM_STATE = 50\n",
        "TRAIN_FRACTION = 0.7\n",
        "\n",
        "def get_data(file, filters='!\"%;[\\\\]^_`{|}~\\t\\n', training_len=50,\n",
        "             lower=False):\n",
        "    \"\"\"Retrieve formatted training and validation data from a file\"\"\"\n",
        "    \n",
        "    data = pd.read_csv(file, parse_dates=['patent_date']).dropna(subset = ['patent_abstract'])\n",
        "    abstracts = [format_sequence(a) for a in list(data['patent_abstract'])]\n",
        "    word_idx, idx_word, num_words, word_counts, texts, sequences, features, labels = make_sequences(\n",
        "        abstracts, training_len, lower, filters)\n",
        "    X_train, X_valid, y_train, y_valid = create_train_valid(features, labels, num_words)\n",
        "    training_dict = {'X_train': X_train, 'X_valid': X_valid, \n",
        "                     'y_train': y_train, 'y_valid': y_valid}\n",
        "    return training_dict, word_idx, idx_word, sequences\n",
        "\n",
        "# Data Preparation- Tokenizer \n",
        "def make_sequences(texts, training_length = 50,\n",
        "                   lower = True, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'):\n",
        "    \"\"\"Turn a set of texts into sequences of integers\"\"\"\n",
        "    \n",
        "    # Create the tokenizer object \n",
        "    tokenizer = Tokenizer(lower=lower, filters=filters)\n",
        "    # Train on texts\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    \n",
        "    # Create look-up dictionaries and reverse look-ups (int -> string)\n",
        "    word_idx = tokenizer.word_index\n",
        "    idx_word = tokenizer.index_word\n",
        "    num_words = len(word_idx) + 1\n",
        "    word_counts = tokenizer.word_counts\n",
        "    \n",
        "    print(f'There are {num_words} unique words.')\n",
        "    \n",
        "    # Convert text to sequences of integers\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    \n",
        "    # Limit to sequences with more than training length tokens\n",
        "    seq_lengths = [len(x) for x in sequences]\n",
        "    over_idx = [i for i, l in enumerate(seq_lengths) if l > (training_length + 20)]\n",
        "    \n",
        "    new_texts = []\n",
        "    new_sequences = []\n",
        "    \n",
        "    # Only keep sequences with more than training length tokens\n",
        "    for i in over_idx:\n",
        "        new_texts.append(texts[i])\n",
        "        new_sequences.append(sequences[i])\n",
        "        \n",
        "    features = []\n",
        "    labels = []\n",
        "    \n",
        "    # Iterate through the sequences of tokens\n",
        "    for seq in new_sequences:\n",
        "        \n",
        "        # Create multiple training examples from each sequence\n",
        "        for i in range(training_length, len(seq)):\n",
        "            # Extract the features and label\n",
        "            extract = seq[i - training_length: i + 1]\n",
        "            \n",
        "            # Set the features and label\n",
        "            features.append(extract[:-1])\n",
        "            labels.append(extract[-1])\n",
        "    \n",
        "    print(f'There are {len(features)} sequences.')\n",
        "    \n",
        "    # Return everything needed for setting up the model\n",
        "    return word_idx, idx_word, num_words, word_counts, new_texts, new_sequences, features, labels\n",
        "\n",
        "\n",
        "# Features and Labels \n",
        "def create_train_valid(features,\n",
        "                       labels,\n",
        "                       num_words,\n",
        "                       train_fraction=0.7):\n",
        "    \"\"\"Create training and validation features and labels.\"\"\"\n",
        "    \n",
        "    # Randomly shuffle features and labels\n",
        "    features, labels = shuffle(features, labels, random_state=RANDOM_STATE)\n",
        "\n",
        "    # Decide on number of samples for training\n",
        "    train_end = int(train_fraction * len(labels))\n",
        "\n",
        "    train_features = np.array(features[:train_end])\n",
        "    valid_features = np.array(features[train_end:])\n",
        "\n",
        "    train_labels = labels[:train_end]\n",
        "    valid_labels = labels[train_end:]\n",
        "\n",
        "    # Convert to arrays\n",
        "    X_train, X_valid = np.array(train_features), np.array(valid_features)\n",
        "\n",
        "    # Using int8 for memory savings\n",
        "    y_train = np.zeros((len(train_labels), num_words), dtype=np.int8)\n",
        "    y_valid = np.zeros((len(valid_labels), num_words), dtype=np.int8)\n",
        "\n",
        "    # One hot encoding of labels\n",
        "    # Neural Network is able to train most effectively when the labels are one-hot encoded\n",
        "    for example_index, word_index in enumerate(train_labels):\n",
        "        y_train[example_index, word_index] = 1\n",
        "\n",
        "    for example_index, word_index in enumerate(valid_labels):\n",
        "        y_valid[example_index, word_index] = 1\n",
        "\n",
        "    # Memory management\n",
        "    import gc\n",
        "    gc.enable()\n",
        "    del features, labels, train_features, valid_features, train_labels, valid_labels\n",
        "    gc.collect()\n",
        "\n",
        "    return X_train, X_valid, y_train, y_valid\n",
        "\n",
        "# Modeling \n",
        "def get_model(model_name):\n",
        "    \"\"\"Retrieve a Keras model and embeddings\"\"\"\n",
        "    model = load_model(f'../models/{model_name}.h5')\n",
        "    embeddings = model.get_layer(index = 0)\n",
        "    embeddings = embeddings.get_weights()[0]\n",
        "    embeddings = embeddings / np.linalg.norm(embeddings, axis = 1).reshape((-1, 1))\n",
        "    embeddings = np.nan_to_num(embeddings)\n",
        "    word_idx = []\n",
        "    with open(f'../data/training-rnn.json', 'rb') as f:\n",
        "        for l in f:\n",
        "            word_idx.append(json.loads(l))\n",
        "        \n",
        "    word_idx = word_idx[0]\n",
        "    word_idx['UNK'] = 0\n",
        "    idx_word = {index: word for word, index in word_idx.items()}\n",
        "    return model, embeddings, word_idx, idx_word\n",
        "\n",
        "def get_embeddings(model):\n",
        "    \"\"\"Retrieve the embeddings in a model\"\"\"\n",
        "    embeddings = model.get_layer(index = 0)\n",
        "    embeddings = embeddings.get_weights()[0]\n",
        "    embeddings = embeddings / np.linalg.norm(embeddings, axis = 1).reshape((-1, 1))\n",
        "    embeddings = np.nan_to_num(embeddings)\n",
        "    return embeddings\n",
        "    \n",
        "def find_closest(query, embedding_matrix, word_idx, idx_word, n = 10):\n",
        "    \"\"\"Find closest words to a query word in embeddings\"\"\"\n",
        "    \n",
        "    idx = word_idx.get(query, None)\n",
        "    # Handle case where query is not in vocab\n",
        "    if idx is None:\n",
        "        print(f'{query} not found in vocab.')\n",
        "        return\n",
        "    else:\n",
        "        vec = embedding_matrix[idx]\n",
        "        # Handle case where word doesn't have an embedding\n",
        "        if np.all(vec == 0):\n",
        "            print(f'{query} has no pre-trained embedding.')\n",
        "            return\n",
        "        else:\n",
        "            # Calculate distance between vector and all others\n",
        "            dists = np.dot(embedding_matrix, vec)\n",
        "            \n",
        "            # Sort indexes in reverse order\n",
        "            idxs = np.argsort(dists)[::-1][:n]\n",
        "            sorted_dists = dists[idxs]\n",
        "            closest = [idx_word[i] for i in idxs]\n",
        "            \n",
        "    print(f'Query: {query}\\n')\n",
        "    # Print out the word and cosine distances\n",
        "    for word, dist in zip(closest, sorted_dists):\n",
        "        print(f'Word: {word:15} Cosine Similarity: {round(dist, 4)}')\n",
        "        \n",
        "def format_sequence(s):\n",
        "    \"\"\"Add spaces around punctuation and remove references to images/citations.\"\"\"\n",
        "    \n",
        "    # Add spaces around punctuation\n",
        "    s =  re.sub(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', s)\n",
        "    \n",
        "    # Remove references to figures\n",
        "    s = re.sub(r'\\((\\d+)\\)', r'', s)\n",
        "    \n",
        "    # Remove double spaces\n",
        "    s = re.sub(r'\\s\\s', ' ', s)\n",
        "    return s\n",
        "\n",
        "def remove_spaces(s):\n",
        "    \"\"\"Remove spaces around punctuation\"\"\"\n",
        "    s = re.sub(r'\\s+([.,;?])', r'\\1', s)\n",
        "    \n",
        "    return s\n",
        "\n",
        "\n",
        "def generate_output(model,\n",
        "                    sequences,\n",
        "                    idx_word,\n",
        "                    seed_length=50,\n",
        "                    new_words=50,\n",
        "                    diversity=1,\n",
        "                    return_output=False,\n",
        "                    n_gen=1):\n",
        "    \"\"\"Generate `new_words` words of output from a trained model and format into HTML.\"\"\"\n",
        "\n",
        "    # Choose a random sequence\n",
        "    seq = random.choice(sequences)\n",
        "\n",
        "    # Choose a random starting point\n",
        "    seed_idx = random.randint(0, len(seq) - seed_length - 10)\n",
        "    # Ending index for seed\n",
        "    end_idx = seed_idx + seed_length\n",
        "\n",
        "    gen_list = []\n",
        "\n",
        "    for n in range(n_gen):\n",
        "        # Extract the seed sequence\n",
        "        seed = seq[seed_idx:end_idx]\n",
        "        original_sequence = [idx_word[i] for i in seed]\n",
        "        generated = seed[:] + ['#']\n",
        "\n",
        "        # Find the actual entire sequence\n",
        "        actual = generated[:] + seq[end_idx:end_idx + new_words]\n",
        "\n",
        "        # Keep adding new words\n",
        "        for i in range(new_words):\n",
        "\n",
        "            # Make a prediction from the seed\n",
        "            preds = model.predict(np.array(seed).reshape(1, -1))[0].astype(\n",
        "                np.float64)\n",
        "\n",
        "            # Diversify\n",
        "            preds = np.log(preds) / diversity\n",
        "            exp_preds = np.exp(preds)\n",
        "\n",
        "            # Softmax\n",
        "            preds = exp_preds / sum(exp_preds)\n",
        "\n",
        "            # Choose the next word\n",
        "            probas = np.random.multinomial(1, preds, 1)[0]\n",
        "\n",
        "            next_idx = np.argmax(probas)\n",
        "\n",
        "            # New seed adds on old word\n",
        "            #             seed = seed[1:] + [next_idx]\n",
        "            seed += [next_idx]\n",
        "            generated.append(next_idx)\n",
        "\n",
        "        # Showing generated and actual abstract\n",
        "        n = []\n",
        "\n",
        "        for i in generated:\n",
        "            n.append(idx_word.get(i, '< --- >'))\n",
        "\n",
        "        gen_list.append(n)\n",
        "\n",
        "    a = []\n",
        "\n",
        "    for i in actual:\n",
        "        a.append(idx_word.get(i, '< --- >'))\n",
        "\n",
        "    a = a[seed_length:]\n",
        "\n",
        "    gen_list = [gen[seed_length:seed_length + len(a)] for gen in gen_list]\n",
        "\n",
        "    if return_output:\n",
        "        return original_sequence, gen_list, a\n",
        "\n",
        "    # HTML formatting\n",
        "    seed_html = ''\n",
        "    seed_html = addContent(seed_html, header(\n",
        "        'Seed Sequence', color='darkblue'))\n",
        "    seed_html = addContent(seed_html,\n",
        "                           box(remove_spaces(' '.join(original_sequence))))\n",
        "\n",
        "    gen_html = ''\n",
        "    gen_html = addContent(gen_html, header('RNN Generated', color='darkred'))\n",
        "    gen_html = addContent(gen_html, box(remove_spaces(' '.join(gen_list[0]))))\n",
        "\n",
        "    a_html = ''\n",
        "    a_html = addContent(a_html, header('Actual', color='darkgreen'))\n",
        "    a_html = addContent(a_html, box(remove_spaces(' '.join(a))))\n",
        "\n",
        "    return seed_html, gen_html, a_html\n",
        "\n",
        "\n",
        "\n",
        "def header(text, color = 'black', gen_text = None):\n",
        "    if gen_text:\n",
        "        raw_html = f'<h1 style=\"color: {color};\"><p><center>' + str(\n",
        "        text) + '<span style=\"color: red\">' + str(gen_text) + '</center></p></h1>'\n",
        "    else:\n",
        "        raw_html = f'<h1 style=\"color: {color};\"><center>' + str(\n",
        "            text) + '</center></h1>'\n",
        "    return raw_html\n",
        "\n",
        "\n",
        "def box(text, gen_text=None):\n",
        "    if gen_text:\n",
        "        raw_html = '<div style=\"border:1px inset black;padding:1em;font-size: 20px;\"> <p>' + str(\n",
        "            text) +'<span style=\"color: red\">' + str(gen_text) + '</p></div>'\n",
        "\n",
        "    else:\n",
        "        raw_html = '<div style=\"border:1px inset black;padding:1em;font-size: 20px;\">' + str(\n",
        "            text) + '</div>'\n",
        "    return raw_html\n",
        "\n",
        "\n",
        "def addContent(old_html, raw_html):\n",
        "    old_html += raw_html\n",
        "    return old_html\n",
        "\n",
        "def seed_sequence(model, s, word_idx, idx_word, \n",
        "                  diversity = 0.75, num_words = 50):\n",
        "    \"\"\"Generate output starting from a seed sequence.\"\"\"\n",
        "    # Original formated text\n",
        "    start = format_sequence(s).split()\n",
        "    gen = []\n",
        "    s = start[:]\n",
        "    # Generate output\n",
        "    for _ in range(num_words):\n",
        "        # Conver to arry\n",
        "        x = np.array([word_idx.get(word, 0) for word in s]).reshape((1, -1))\n",
        "\n",
        "        # Make predictions\n",
        "        preds = model.predict(x)[0].astype(float)\n",
        "\n",
        "        # Diversify\n",
        "        preds = np.log(preds) / diversity\n",
        "        exp_preds = np.exp(preds)\n",
        "        # Softmax\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "        # Pick next index\n",
        "        next_idx = np.argmax(np.random.multinomial(1, preds, size = 1))\n",
        "        s.append(idx_word[next_idx])\n",
        "        gen.append(idx_word[next_idx])\n",
        "    \n",
        "    # Formatting in html\n",
        "    start = remove_spaces(' '.join(start)) + ' '\n",
        "    gen = remove_spaces(' '.join(gen)) \n",
        "    html = ''\n",
        "    html = addContent(html, header('Input Seed ', color = 'black', gen_text = 'Network Output'))\n",
        "    html = addContent(html, box(start, gen))\n",
        "    return html\n",
        "\n",
        "def guess_human(model, sequences, idx_word, seed_length=50):\n",
        "    \"\"\"Produce 2 RNN sequences and play game to compare to actaul.\n",
        "       Diversity is randomly set between 0.5 and 1.25\"\"\"\n",
        "    \n",
        "    new_words = np.random.randint(10, 50)\n",
        "    diversity = np.random.uniform(0.5, 1.25)\n",
        "    sequence, gen_list, actual = generate_output(model, sequences, idx_word, seed_length, new_words,\n",
        "                                                 diversity=diversity, return_output=True, n_gen = 2)\n",
        "    gen_0, gen_1 = gen_list\n",
        "    \n",
        "    output = {'sequence': remove_spaces(' '.join(sequence)),\n",
        "              'computer0': remove_spaces(' '.join(gen_0)),\n",
        "              'computer1': remove_spaces(' '.join(gen_1)),\n",
        "              'human': remove_spaces(' '.join(actual))}\n",
        "    \n",
        "    print(f\"Seed Sequence: {output['sequence']}\\n\")\n",
        "    \n",
        "    choices = ['human', 'computer0', 'computer1']\n",
        "          \n",
        "    selected = []\n",
        "    i = 0\n",
        "    while len(selected) < 3:\n",
        "        choice = random.choice(choices)\n",
        "        selected.append(choice)\n",
        "        print(f'\\nOption {i + 1} {output[choice]}')\n",
        "        choices.remove(selected[-1])\n",
        "        i += 1\n",
        "    \n",
        "    print('\\n')\n",
        "    guess = int(input('Enter option you think is human (1-3): ')) - 1\n",
        "    print('\\n')\n",
        "    \n",
        "    if guess == np.where(np.array(selected) == 'human')[0][0]:\n",
        "        print('*' * 3 + 'Correct' + '*' * 3 + '\\n')\n",
        "        print('-' * 60)\n",
        "        print('Ordering: ', selected)\n",
        "    else:\n",
        "        print('*' * 3 + 'Incorrect' + '*' * 3 + '\\n')\n",
        "        print('-' * 60)\n",
        "        print('Correct Ordering: ', selected)\n",
        "          \n",
        "    print('Diversity', round(diversity, 2))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5kldVzc8-5q"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "from IPython.display import HTML\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category = RuntimeWarning)\n",
        "warnings.filterwarnings('ignore', category = UserWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from utils import get_data, generate_output, guess_human, seed_sequence, get_embeddings, find_closest"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "YD7o-Da_8-8a",
        "outputId": "7eac6f25-0b7d-44e4-b90a-48fccfb7a636"
      },
      "source": [
        "df = pd.read_csv(patent)\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patent_abstract</th>\n",
              "      <th>patent_date</th>\n",
              "      <th>patent_number</th>\n",
              "      <th>patent_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\" A \"\"Barometer\"\" Neuron enhances stability in...</td>\n",
              "      <td>1996-07-09</td>\n",
              "      <td>5535303</td>\n",
              "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" This invention is a novel high-speed neural ...</td>\n",
              "      <td>1993-10-19</td>\n",
              "      <td>5255349</td>\n",
              "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An optical information processor for use as a ...</td>\n",
              "      <td>1995-01-17</td>\n",
              "      <td>5383042</td>\n",
              "      <td>3 layer liquid crystal neural network with out...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A method and system for intelligent control of...</td>\n",
              "      <td>2001-01-02</td>\n",
              "      <td>6169981</td>\n",
              "      <td>3-brain architecture for an intelligent decisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A method and system for intelligent control of...</td>\n",
              "      <td>2003-06-17</td>\n",
              "      <td>6581048</td>\n",
              "      <td>3-brain architecture for an intelligent decisi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     patent_abstract  ...                                       patent_title\n",
              "0  \" A \"\"Barometer\"\" Neuron enhances stability in...  ...        \"\"\"Barometer\"\" neuron for a neural network\"\n",
              "1  \" This invention is a novel high-speed neural ...  ...  \"Electronic neural network for solving \"\"trave...\n",
              "2  An optical information processor for use as a ...  ...  3 layer liquid crystal neural network with out...\n",
              "3  A method and system for intelligent control of...  ...  3-brain architecture for an intelligent decisi...\n",
              "4  A method and system for intelligent control of...  ...  3-brain architecture for an intelligent decisi...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j0x9xnM7ZUt"
      },
      "source": [
        "### 1) Data Preparation\n",
        "1. Remove punctuation and split strings into lists of individual words\n",
        "2. Convert the individual words into integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMahheId8-_M",
        "outputId": "24b41f21-c6ac-41a6-df24-0837ed154b61"
      },
      "source": [
        "training_dict, word_idx, idx_word, sequences = get_data(patent, training_len = 50)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 16192 unique words.\n",
            "There are 318563 sequences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "503kKp2n8_B1",
        "outputId": "5e93ccc1-b8a3-4bc1-962f-197e5068b2e1"
      },
      "source": [
        "training_dict['X_train'][:2]\n",
        "training_dict['y_train'][:2]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  117,     7,   141,   277,     4,    18,    81,   110,    10,\n",
              "          219,    29,     1,   952,  2453,    19,     5,     6,     1,\n",
              "          117,    10,   182,  2166,    21,     1,    81,   178,     4,\n",
              "           13,   117,   894,    14,  6163,     7,   302,     1,     9,\n",
              "            8,    29,    33,    23,    74,   428,     7,   692,     1,\n",
              "           81,   183,     4,    13,   117],\n",
              "       [    6,    41,     2,    87,     3,  1340,    79,     7,     1,\n",
              "          409,   543,    22,   484,     6,     2,  2113,   728,    24,\n",
              "            1,   178,     3,     1,  1820,    55,    14, 13942,  7240,\n",
              "          244,     5,    14, 13943,  7240,   244,     5,     2,  2113,\n",
              "         7240,   244,     5,     2,    38,  9292,   244,     2,    49,\n",
              "         9292,   244,    14,    22, 13944]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkKSC78CFiuO"
      },
      "source": [
        "### 2) Features and Labels \n",
        "1. Use the first 50 words as Features and 51th as the Label (반복) \n",
        "2. Features shape (296866, 50)\n",
        "  - 30000 sequences each with 50 tokens \n",
        "  - 50 timesteps each with 1 feature \n",
        "3. Label One-hot encoding \n",
        "  - to train most effectively "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tpwsJ2sDr-n"
      },
      "source": [
        "- idx_word : attribute of the trained tokenizer to figure out what each of these integers means \n",
        "  - 정수를 문자열로 변환하여 내용을 확인 할 수 있다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdIMO7ye8_Ep",
        "outputId": "5e296ab2-e02a-4367-a6b7-0b0c8061658b"
      },
      "source": [
        "for i, sequence in enumerate(training_dict['X_train'][:2]):\n",
        "    text = []\n",
        "    for idx in sequence:\n",
        "        text.append(idx_word[idx])\n",
        "\n",
        "# features: 단어 50개 \n",
        "# labels : 51번째 단어  \n",
        "      \n",
        "    print('Features: ' + ' '.join(text) + '\\n')\n",
        "    print('Label: ' + idx_word[np.argmax(training_dict['y_train'][i])] + '\\n')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: user to provide samples . A recognition operation is performed on the user's handwritten input , and the user is not satisfied with the recognition result . The user selects an option to train the neural network on one or more characters to improve the recognition results . The user\n",
            "\n",
            "Label: is\n",
            "\n",
            "Features: and includes a number of amplifiers corresponding to the N bit output sum and a carry generation from the result of the adding process an augend input-synapse group , an addend input-synapse group , a carry input-synapse group , a first bias-synapse group a second bias-synapse group an output feedback-synapse\n",
            "\n",
            "Label: group\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kR0JZSPEevB"
      },
      "source": [
        "### 3) Modeling\n",
        "1. Build LSTM model with Embedding, LSTM, and Dense layers\n",
        "3. Train model to predict next work in sequence\n",
        "4. Make predictions by passing in starting sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuOFw88g8_HT"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OSLgaqr8_J-",
        "outputId": "b9489663-a2e4-4185-ebad-2066c3e50685"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(Embedding(input_dim=len(word_idx) + 1, output_dim=100, weights=None, trainable=True)) \n",
        "# Recurrent layer : dropout will prevent overfitting \n",
        "model.add(LSTM(64, return_sequences=False, dropout=0.1, recurrent_dropout=0.1))  \n",
        "# Fully connected layer \n",
        "model.add(Dense(64, activation='relu'))  \n",
        "# Dropout for regularization \n",
        "model.add(Dropout(0.5))  \n",
        "# Output layer : produce a probability for using softmax activation \n",
        "model.add(Dense(len(word_idx) + 1, activation='softmax'))   \n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         1619200   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16192)             1052480   \n",
            "=================================================================\n",
            "Total params: 2,718,080\n",
            "Trainable params: 2,718,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFw6XQRg8_Mw",
        "outputId": "ff334bbf-4dcd-4d7d-9930-f526375656f0"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load in model and demonstrate training\n",
        "model = load_model(embedding1)\n",
        "h = model.fit(training_dict['X_train'], training_dict['y_train'], epochs = 5, batch_size = 2048, \n",
        "          validation_data = (training_dict['X_valid'], training_dict['y_valid']), \n",
        "          verbose = 1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "109/109 [==============================] - 325s 3s/step - loss: 3.7533 - accuracy: 0.2953 - val_loss: 5.1503 - val_accuracy: 0.2670\n",
            "Epoch 2/5\n",
            "109/109 [==============================] - 314s 3s/step - loss: 3.7381 - accuracy: 0.2962 - val_loss: 5.1584 - val_accuracy: 0.2679\n",
            "Epoch 3/5\n",
            "109/109 [==============================] - 323s 3s/step - loss: 3.7242 - accuracy: 0.2978 - val_loss: 5.1603 - val_accuracy: 0.2687\n",
            "Epoch 4/5\n",
            "109/109 [==============================] - 331s 3s/step - loss: 3.7130 - accuracy: 0.2978 - val_loss: 5.1642 - val_accuracy: 0.2691\n",
            "Epoch 5/5\n",
            "109/109 [==============================] - 314s 3s/step - loss: 3.6983 - accuracy: 0.2992 - val_loss: 5.1885 - val_accuracy: 0.2691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWyV_NB2Ua8b"
      },
      "source": [
        "- Evaliating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWy0FPG78_Pb",
        "outputId": "c5b0a5d8-17ef-491b-91bc-b817d3973e13"
      },
      "source": [
        "model = load_model(embedding1)\n",
        "print('Model Performance: Log Loss and Accuracy on training data')\n",
        "model.evaluate(training_dict['X_train'], training_dict['y_train'], batch_size = 2048)\n",
        "\n",
        "print('\\nModel Performance: Log Loss and Accuracy on validation data')\n",
        "model.evaluate(training_dict['X_valid'], training_dict['y_valid'], batch_size = 2048)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance: Log Loss and Accuracy on training data\n",
            "109/109 [==============================] - 88s 800ms/step - loss: 3.2897 - accuracy: 0.3384\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.289726495742798, 0.3384440839290619]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance: Log Loss and Accuracy on validation data\n",
            "47/47 [==============================] - 37s 791ms/step - loss: 5.1321 - accuracy: 0.2672\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.132135391235352, 0.2671891450881958]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5o9a6J6Ui4G"
      },
      "source": [
        "### Patent Abstract Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m53xAkDA8_VB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "4dbdf7d1-4a68-4cb5-d077-641b033d258d"
      },
      "source": [
        "for i in generate_output(model, sequences, idx_word, seed_length = 50, new_words = 30, diversity = 0.75):\n",
        "    HTML(i)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">, and execute instructions. The N neuron structure should contain communicating adder trees, neuron activation function units, and an arrangement for communicating both instructions, data, and the outputs of neuron activation function units back to the input synapse processing units by means of the communicating</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">< --- > adder that the all neurons are shared by an output layer interconnected to the neuron population. The training neural network weight is then connected to the neural network to</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">< --- > adder trees. The apparatus can be structured as a bit-serial or word parallel system. The preferred structure contains N.sup.2 synapse processing units, each associated with</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2UFDKnX8_X2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "2349c9ff-9351-456a-a5a5-a7bff8536110"
      },
      "source": [
        "for i in generate_output(model, sequences, idx_word, seed_length = 30, new_words = 30, diversity = 1.5):\n",
        "    HTML(i)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">, for example, providing by a processor a real-time representation of an artificial neural network and of graphical effects of a running of the neural network. A system</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">< --- > further relates adaptive classifier (e.g. the tree are labeled by the new user. Sets of representative neuron outputs</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">< --- > and method includes, for example, automatically modifying the behavior of network nodes based on simultaneous occurrences of events.</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgIFoQPN8_ag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8e640429-435d-4790-9f32-4b0a9574336c"
      },
      "source": [
        "s = 'This patent provides a basis for using a recurrent neural network to '\n",
        "HTML(seed_sequence(model, s, word_idx, idx_word, diversity = 0.75, num_words = 20))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1 style=\"color: black;\"><p><center>Input Seed <span style=\"color: red\">Network Output</center></p></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\"> <p>This patent provides a basis for using a recurrent neural network to <span style=\"color: red\">increase of more efficient. In an identification method, the method also provides output data representing the sensible representation</p></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJVbecKH8_dW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8a000bb3-d167-4605-8cf0-d86ab550f944"
      },
      "source": [
        "s = 'The cell state is passed along from one time step to another allowing the '\n",
        "HTML(seed_sequence(model, s, word_idx, idx_word, diversity = 0.75, num_words = 20))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1 style=\"color: black;\"><p><center>Input Seed <span style=\"color: red\">Network Output</center></p></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\"> <p>The cell state is passed along from one time step to another allowing the <span style=\"color: red\">activation value for applying a second input signal from the neural network, and the synapse load is adjusted from</p></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHxrW6hkVqLV"
      },
      "source": [
        "### Guess Game: Human or Machine? 🕹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3pfGQjz8_f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be31dfa1-a1b8-4bf9-c3da-590e38d41641"
      },
      "source": [
        "guess_human(model, sequences, idx_word)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed Sequence: a problem data set representing items associated with the problem is obtained. Evaluation data indicating a state of learning obtained during the learning on the current problem is sequentially stored and displayed. When there is a high possibility of learning protraction during the learning, a message informing\n",
            "\n",
            "\n",
            "Option 1 < --- > the result of the second metadata are assigned to the phonetic sets of nodes. An activation vector is classified as the linear layer. The network can also be integrated\n",
            "\n",
            "Option 2 < --- > the user is displayed. When the learning is stopped by the user in this case, the problem data set and evaluation data set are stored. Then, a\n",
            "\n",
            "Option 3 < --- > the linear process, a new input layer of a certain set can also as a neural network for drawing the shot component of the extracted convolutional neural network. The\n",
            "\n",
            "\n",
            "Enter option you think is human (1-3): 2\n",
            "\n",
            "\n",
            "***Correct***\n",
            "\n",
            "------------------------------------------------------------\n",
            "Ordering:  ['computer0', 'human', 'computer1']\n",
            "Diversity 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQswppjZ8_ip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f47c365-2601-4f98-cd2e-b18d705d629d"
      },
      "source": [
        "guess_human(model, sequences, idx_word)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed Sequence: between the applied energization control and the motor's response may be employed by a neural network to estimate the regions of operation of the motor. And a system for controlling the operation of motor may employ this information, the neural network, or both to regulate the energization\n",
            "\n",
            "\n",
            "Option 1 < --- > of a motor's phase winding during a phase cycle.\n",
            "\n",
            "Option 2 < --- > or transparent refractor and the presence of incident photons.\n",
            "\n",
            "Option 3 < --- > or to eliminate the optical system. The method also\n",
            "\n",
            "\n",
            "Enter option you think is human (1-3): 4\n",
            "\n",
            "\n",
            "***Incorrect***\n",
            "\n",
            "------------------------------------------------------------\n",
            "Correct Ordering:  ['human', 'computer0', 'computer1']\n",
            "Diversity 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUAmxok08_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19f3840-1b02-418a-a863-845d4d3c4ff2"
      },
      "source": [
        "guess_human(model, sequences, idx_word)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed Sequence: to pass through a variable conductance. The conductance is a function of the states of the one or more interconnecting neighboring cells. Proper interconnection of the cells on a layer can produce a neural network which is sensitive to predetermined patterns or the passage of such patterns across\n",
            "\n",
            "\n",
            "Option 1 < --- > the coupling pairs in a neural network which further provide the information into such matching an low amplitude that between the cells characterized. The positive distributions of the time by the distance in the same weighted function may be employed and so\n",
            "\n",
            "Option 2 < --- > a sensor array whose signals are input into the network. The layers in the network can be made sensitive to distinct sensory parameters, so that networks which are sensitive to different wavelengths or polarizations of light energy can be produced.\n",
            "\n",
            "Option 3 < --- > the charge based upon processing the internal state. Accordingly, or additionally includes: one mode for a geophysical amount to generate the operation of these representations from each part extracted. The combined learning is completed the segmented images within these representations\n",
            "\n",
            "\n",
            "Enter option you think is human (1-3): 2\n",
            "\n",
            "\n",
            "***Correct***\n",
            "\n",
            "------------------------------------------------------------\n",
            "Ordering:  ['computer1', 'human', 'computer0']\n",
            "Diversity 1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz-nOSuNXuxA"
      },
      "source": [
        "### Building Modeling: Pre-trained Embeddings\n",
        "  - Use Glove algorithm and trained on Wikipedia \n",
        "  - Notincluded in word embeddings ➡️ **100-d vectors of all zeros**\n",
        "    - Train own embeddings or Set the Embedding layer's trainable= True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQSbozpc8_oa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd74b35-883e-4200-bda7-faa08a048830"
      },
      "source": [
        "embeddings = get_embeddings(model)\n",
        "embeddings.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16192, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pK0oGn2azoS"
      },
      "source": [
        "- Using Cosine Similarity \n",
        "   - find the words closests to a given query word in the embedding space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNsaAbYj8_rH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd1e455-19d4-4f86-adf9-c747fbf7a49e"
      },
      "source": [
        "find_closest('network', embeddings, word_idx, idx_word)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: network\n",
            "\n",
            "Word: network         Cosine Similarity: 1.0\n",
            "Word: channel         Cosine Similarity: 0.7754999995231628\n",
            "Word: networks        Cosine Similarity: 0.7745000123977661\n",
            "Word: system          Cosine Similarity: 0.7559999823570251\n",
            "Word: program         Cosine Similarity: 0.7541999816894531\n",
            "Word: cable           Cosine Similarity: 0.7419999837875366\n",
            "Word: now             Cosine Similarity: 0.7297999858856201\n",
            "Word: programming     Cosine Similarity: 0.7179999947547913\n",
            "Word: web             Cosine Similarity: 0.7138000130653381\n",
            "Word: line            Cosine Similarity: 0.6915000081062317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93hJKZ_YCDpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8f69b0-816c-48a8-f71b-1c7c89da494d"
      },
      "source": [
        "find_closest('data', embeddings, word_idx, idx_word)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: data\n",
            "\n",
            "Word: data            Cosine Similarity: 1.0\n",
            "Word: information     Cosine Similarity: 0.8185999989509583\n",
            "Word: numbers         Cosine Similarity: 0.683899998664856\n",
            "Word: database        Cosine Similarity: 0.6776000261306763\n",
            "Word: account         Cosine Similarity: 0.6575999855995178\n",
            "Word: report          Cosine Similarity: 0.6575999855995178\n",
            "Word: signals         Cosine Similarity: 0.6399999856948853\n",
            "Word: system          Cosine Similarity: 0.6377000212669373\n",
            "Word: statistics      Cosine Similarity: 0.6371999979019165\n",
            "Word: web             Cosine Similarity: 0.6359000205993652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmdN9XGrCDuM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvSEGg-KCD0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a070ae9-09b3-4032-c5f6-31045ef9e645"
      },
      "source": [
        "import requests \n",
        "\n",
        "response = requests.get('https://google.com/') \n",
        "print(response) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpblypvDCD4x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjiL7ZB6CD9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a013ade5-4d9d-4857-a841-2de629481311"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "max_features = 10000\n",
        "max_len = 500\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) \n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 500)\n",
            "x_test shape: (25000, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYmOQvV3CEB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d0a721-413b-4f9f-c2c9-cb5cd8e74309"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_features, 128, input_length=max_len))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(1))\n",
        "model.summary()\n",
        "model.compile(optimizer=RMSprop(lr=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 494, 32)           28704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 98, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 92, 32)            7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,315,937\n",
            "Trainable params: 1,315,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 72s 456ms/step - loss: 0.7296 - acc: 0.5204 - val_loss: 0.6856 - val_acc: 0.5744\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 71s 455ms/step - loss: 0.6686 - acc: 0.6603 - val_loss: 0.6711 - val_acc: 0.6370\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 71s 455ms/step - loss: 0.6370 - acc: 0.7475 - val_loss: 0.6386 - val_acc: 0.7004\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 72s 456ms/step - loss: 0.5750 - acc: 0.7964 - val_loss: 0.5536 - val_acc: 0.7778\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 71s 455ms/step - loss: 0.4633 - acc: 0.8263 - val_loss: 0.4567 - val_acc: 0.8184\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 71s 455ms/step - loss: 0.3744 - acc: 0.8595 - val_loss: 0.4215 - val_acc: 0.8436\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 72s 456ms/step - loss: 0.3251 - acc: 0.8827 - val_loss: 0.4043 - val_acc: 0.8580\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 72s 456ms/step - loss: 0.2909 - acc: 0.8957 - val_loss: 0.4271 - val_acc: 0.8602\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 71s 455ms/step - loss: 0.2605 - acc: 0.9090 - val_loss: 0.4643 - val_acc: 0.8574\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 71s 454ms/step - loss: 0.2343 - acc: 0.9186 - val_loss: 0.4605 - val_acc: 0.8698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQE7QskCEGd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7MId5LiCEMC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw_sjo5kCEP2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IAWDepA8_t3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}